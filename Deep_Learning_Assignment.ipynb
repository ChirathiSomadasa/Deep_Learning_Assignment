{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChirathiSomadasa/Deep_Learning_Assignment/blob/main/Deep_Learning_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Plant Disease Classification**\n"
      ],
      "metadata": {
        "id": "3EbAT5CLjlBa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Somadasa N.M.C.U. - IT22354242**"
      ],
      "metadata": {
        "id": "Mj5R3LBQjz4w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transfer Learning Specialist — MobileNetV2"
      ],
      "metadata": {
        "id": "Nxo-zofdkCAB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 1: Mount Google Drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-rONtf_uC2L",
        "outputId": "520b3b0b-82ae-451a-a5b2-548d3fd54644"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip\n",
        "!unzip -q -o \"/content/drive/MyDrive/DL/PlantVillage.zip\" -d \"/content/PlantVillage\""
      ],
      "metadata": {
        "id": "D9GLt18UuFpj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvdfYCkFsdTi",
        "outputId": "5e349c48-9b9e-4c52-d208-275cf7b835cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2362 images belonging to 16 classes.\n",
            "Found 590 images belonging to 16 classes.\n",
            "Training samples: 2362, Validation samples: 590\n",
            "Classes: {'Pepper__bell___Bacterial_spot': 0, 'Pepper__bell___healthy': 1, 'Potato___Early_blight': 2, 'Potato___Late_blight': 3, 'Potato___healthy': 4, 'Tomato_Bacterial_spot': 5, 'Tomato_Early_blight': 6, 'Tomato_Late_blight': 7, 'Tomato_Leaf_Mold': 8, 'Tomato_Septoria_leaf_spot': 9, 'Tomato_Spider_mites_Two_spotted_spider_mite': 10, 'Tomato__Target_Spot': 11, 'Tomato__Tomato_YellowLeaf__Curl_Virus': 12, 'Tomato__Tomato_mosaic_virus': 13, 'Tomato_healthy': 14, 'plantvillage': 15}\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_128_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 912ms/step - accuracy: 0.3218 - loss: 2.2965 - val_accuracy: 0.6661 - val_loss: 1.0347\n",
            "Epoch 2/5\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 758ms/step - accuracy: 0.6623 - loss: 1.0477 - val_accuracy: 0.7610 - val_loss: 0.7599\n",
            "Epoch 3/5\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 721ms/step - accuracy: 0.7313 - loss: 0.8193 - val_accuracy: 0.7881 - val_loss: 0.6632\n",
            "Epoch 4/5\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 756ms/step - accuracy: 0.7930 - loss: 0.6854 - val_accuracy: 0.7864 - val_loss: 0.6185\n",
            "Epoch 5/5\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 713ms/step - accuracy: 0.8055 - loss: 0.5895 - val_accuracy: 0.7932 - val_loss: 0.5868\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 599ms/step - accuracy: 0.8003 - loss: 0.6306\n",
            "Validation Accuracy: 0.81\n"
          ]
        }
      ],
      "source": [
        "# 2️ Fix folder structure if nested\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# Check if inner folder exists\n",
        "inner_dir = \"/content/PlantVillage/PlantVillage\"\n",
        "if os.path.exists(inner_dir):\n",
        "    for folder in os.listdir(inner_dir):\n",
        "        src = os.path.join(inner_dir, folder)\n",
        "        dst = os.path.join(\"/content/PlantVillage\", folder)\n",
        "        shutil.move(src, dst)\n",
        "    os.rmdir(inner_dir)\n",
        "\n",
        "\n",
        "# 3️ Create smaller dataset for fast demo\n",
        "\n",
        "original_dir = \"/content/PlantVillage\"\n",
        "fast_dir = \"/content/PlantVillage_FastDemo\"\n",
        "images_per_class = 200  # reduce per class for fast execution\n",
        "\n",
        "if not os.path.exists(fast_dir):\n",
        "    os.makedirs(fast_dir)\n",
        "\n",
        "for class_name in os.listdir(original_dir):\n",
        "    class_path = os.path.join(original_dir, class_name)\n",
        "    if os.path.isdir(class_path):\n",
        "        fast_class_path = os.path.join(fast_dir, class_name)\n",
        "        os.makedirs(fast_class_path, exist_ok=True)\n",
        "\n",
        "        # Copy only image files (ignore subfolders)\n",
        "        img_files = [f for f in os.listdir(class_path) if os.path.isfile(os.path.join(class_path, f))]\n",
        "        img_files = img_files[:images_per_class]  # limit per class\n",
        "\n",
        "        for img in img_files:\n",
        "            src = os.path.join(class_path, img)\n",
        "            dst = os.path.join(fast_class_path, img)\n",
        "            shutil.copy(src, dst)\n",
        "\n",
        "\n",
        "# 4️ Data preprocessing & augmentation\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.2,\n",
        "    rotation_range=20,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "train_data = datagen.flow_from_directory(\n",
        "    fast_dir,\n",
        "    target_size=(128,128),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='training',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_data = datagen.flow_from_directory(\n",
        "    fast_dir,\n",
        "    target_size=(128,128),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='validation',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "print(f\"Training samples: {train_data.samples}, Validation samples: {val_data.samples}\")\n",
        "print(\"Classes:\", train_data.class_indices)\n",
        "\n",
        "\n",
        "# 5️ Build MobileNetV2 model\n",
        "\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(128,128,3))\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "output = Dense(train_data.num_classes, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "# Compile\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "early_stop = EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True)\n",
        "\n",
        "\n",
        "# 6️ Train model\n",
        "\n",
        "history = model.fit(train_data, validation_data=val_data, epochs=5, callbacks=[early_stop])\n",
        "\n",
        "\n",
        "# 7️ Evaluate model\n",
        "\n",
        "loss, acc = model.evaluate(val_data)\n",
        "print(f\"Validation Accuracy: {acc:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# 1️ Path to your test image\n",
        "\n",
        "img_path = \"/content/PlantVillage/Pepper__bell___Bacterial_spot/0022d6b7-d47c-4ee2-ae9a-392a53f48647___JR_B.Spot 8964.JPG\"\n",
        "\n",
        "\n",
        "# 2️ Load & preprocess image\n",
        "\n",
        "img = image.load_img(img_path, target_size=(128,128))\n",
        "img_array = image.img_to_array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "img_array = img_array / 255.0  # rescale\n",
        "\n",
        "\n",
        "# 3️ Predict\n",
        "\n",
        "pred = model.predict(img_array)\n",
        "class_index = np.argmax(pred, axis=1)[0]\n",
        "\n",
        "\n",
        "# 4️ Map prediction to class label\n",
        "\n",
        "# Make sure to invert the class_indices dict\n",
        "class_labels = {v: k for k, v in train_data.class_indices.items()}\n",
        "predicted_label = class_labels[class_index]\n",
        "\n",
        "print(f\"Predicted Disease: {predicted_label}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Cl3lXWvzu-S",
        "outputId": "5aeadee5-04d5-43e7-f45d-e296ed106c84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "Predicted Disease: Pepper__bell___Bacterial_spot\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Balasooriya B.M.P.U.  -  IT22927248**"
      ],
      "metadata": {
        "id": "uf7SJHSFiIdA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transfer Leaning Specialist - Custom CNN"
      ],
      "metadata": {
        "id": "oB2dnGzsiRy2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMwmwpiQim0-",
        "outputId": "b0c9ad60-7806-47ea-d8e2-58374659f1b9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip the dataset\n",
        "\n",
        "!unzip -q -o \"/content/drive/MyDrive/DL/PlantVillage.zip\" -d \"/content/PlantVillage\""
      ],
      "metadata": {
        "id": "EwSy94jojGoa"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fix folder structure if nested\n",
        "\n",
        "import os\n",
        "import shutil"
      ],
      "metadata": {
        "id": "ssGKOjbDjTn_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if inner folder exists\n",
        "\n",
        "inner_dir = \"/content/PlantVillage/PlantVillage\"\n",
        "if os.path.exists(inner_dir):\n",
        "    for folder in os.listdir(inner_dir):\n",
        "        src = os.path.join(inner_dir, folder)\n",
        "        dst = os.path.join(\"/content/PlantVillage\", folder)\n",
        "        shutil.move(src, dst)\n",
        "    os.rmdir(inner_dir)"
      ],
      "metadata": {
        "id": "sX6mhr_8jWcz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create smaller dataset for fast demo (optional)\n",
        "original_dir = \"/content/PlantVillage\"\n",
        "fast_dir = \"/content/PlantVillage_FastDemo\"\n",
        "images_per_class = 200  # reduce per class for fast execution\n",
        "\n",
        "if not os.path.exists(fast_dir):\n",
        "    os.makedirs(fast_dir)\n",
        "\n",
        "for class_name in os.listdir(original_dir):\n",
        "    class_path = os.path.join(original_dir, class_name)\n",
        "    if os.path.isdir(class_path):\n",
        "        fast_class_path = os.path.join(fast_dir, class_name)\n",
        "        os.makedirs(fast_class_path, exist_ok=True)\n",
        "\n",
        "        # Copy only image files (ignore subfolders)\n",
        "        img_files = [f for f in os.listdir(class_path) if os.path.isfile(os.path.join(class_path, f))]\n",
        "        img_files = img_files[:images_per_class]  # limit per class\n",
        "\n",
        "        for img in img_files:\n",
        "            src = os.path.join(class_path, img)\n",
        "            dst = os.path.join(fast_class_path, img)\n",
        "            shutil.copy(src, dst)\n",
        "\n",
        "# Use the fast demo directory for training\n",
        "data_dir = fast_dir\n",
        "\n",
        "# Remove any empty directories\n",
        "for class_name in os.listdir(data_dir):\n",
        "    class_path = os.path.join(data_dir, class_name)\n",
        "    if os.path.isdir(class_path):\n",
        "        if len(os.listdir(class_path)) == 0:  # If folder is empty\n",
        "            os.rmdir(class_path)\n",
        "            print(f\"Removed empty directory: {class_name}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xh0aKsxjazP",
        "outputId": "e9830d3f-bc29-4637-ffb2-445dc2f3b9b8"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removed empty directory: plantvillage\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create datasets using the modern approach\n",
        "import tensorflow as tf\n",
        "\n",
        "img_size = (128, 128)\n",
        "batch_size = 32\n",
        "\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=123,\n",
        "    image_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    label_mode='categorical'\n",
        ")\n",
        "\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=123,\n",
        "    image_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    label_mode='categorical'\n",
        ")\n",
        "\n",
        "# Get class names\n",
        "class_names = train_ds.class_names\n",
        "num_classes = len(class_names)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNiZ0y8Nsf-Y",
        "outputId": "e9e654c7-8b81-492d-fff8-d01378ecfa46"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2952 files belonging to 15 classes.\n",
            "Using 2362 files for training.\n",
            "Found 2952 files belonging to 15 classes.\n",
            "Using 590 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply data augmentation to training dataset\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "def augment_images(image, label):\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    image = tf.image.random_brightness(image, 0.2)\n",
        "    image = tf.image.random_contrast(image, 0.8, 1.2)\n",
        "    image = tf.image.random_saturation(image, 0.8, 1.2)\n",
        "    image = tf.image.random_hue(image, 0.1)\n",
        "    return image, label\n",
        "\n",
        "# Apply augmentation only to training data\n",
        "train_ds = train_ds.map(augment_images)\n",
        "# Normalize both datasets\n",
        "train_ds = train_ds.map(lambda x, y: (x/255.0, y))\n",
        "val_ds = val_ds.map(lambda x, y: (x/255.0, y))\n",
        "\n",
        "# Optimize performance\n",
        "train_ds = train_ds.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "print(f\"Training samples: {len(train_ds) * batch_size}\")\n",
        "print(f\"Validation samples: {len(val_ds) * batch_size}\")\n",
        "print(f\"Number of classes: {num_classes}\")\n",
        "print(f\"Classes: {class_names}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHFRcL7UkKdi",
        "outputId": "48287825-f03a-4bad-afc7-c4b44bf29e69"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training samples: 2368\n",
            "Validation samples: 608\n",
            "Number of classes: 15\n",
            "Classes: ['Pepper__bell___Bacterial_spot', 'Pepper__bell___healthy', 'Potato___Early_blight', 'Potato___Late_blight', 'Potato___healthy', 'Tomato_Bacterial_spot', 'Tomato_Early_blight', 'Tomato_Late_blight', 'Tomato_Leaf_Mold', 'Tomato_Septoria_leaf_spot', 'Tomato_Spider_mites_Two_spotted_spider_mite', 'Tomato__Target_Spot', 'Tomato__Tomato_YellowLeaf__Curl_Virus', 'Tomato__Tomato_mosaic_virus', 'Tomato_healthy']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Design the custom CNN architecture\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Create the model\n",
        "model = Sequential([\n",
        "    # Input layer\n",
        "    Input(shape=(128, 128, 3)),\n",
        "\n",
        "    # First convolutional block\n",
        "    Conv2D(32, (3, 3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Dropout(0.25),\n",
        "\n",
        "    # Second convolutional block\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Dropout(0.25),\n",
        "\n",
        "    # Third convolutional block\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Dropout(0.25),\n",
        "\n",
        "    # Fourth convolutional block\n",
        "    Conv2D(256, (3, 3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Dropout(0.25),\n",
        "\n",
        "    # Flatten the feature maps\n",
        "    Flatten(),\n",
        "\n",
        "    # Fully connected layers\n",
        "    Dense(512, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "\n",
        "    Dense(256, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "\n",
        "    # Output layer\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "L3UrLfagkpHN"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define callbacks\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.2,\n",
        "    patience=5,\n",
        "    min_lr=0.00001\n",
        ")"
      ],
      "metadata": {
        "id": "QwqeZcYhlQGq"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    epochs=30,\n",
        "    validation_data=val_ds,\n",
        "    callbacks=[early_stop, reduce_lr],\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4wsYT3otIpq",
        "outputId": "2940e628-1101-470c-a1aa-7e4a5387a88d"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 2s/step - accuracy: 0.2429 - loss: 2.9632 - val_accuracy: 0.0593 - val_loss: 19.1862 - learning_rate: 0.0010\n",
            "Epoch 2/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 2s/step - accuracy: 0.4549 - loss: 1.7416 - val_accuracy: 0.0593 - val_loss: 23.5493 - learning_rate: 0.0010\n",
            "Epoch 3/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 2s/step - accuracy: 0.5681 - loss: 1.4071 - val_accuracy: 0.0593 - val_loss: 24.7613 - learning_rate: 0.0010\n",
            "Epoch 4/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 2s/step - accuracy: 0.6147 - loss: 1.1443 - val_accuracy: 0.0644 - val_loss: 17.8341 - learning_rate: 0.0010\n",
            "Epoch 5/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 2s/step - accuracy: 0.6657 - loss: 0.9975 - val_accuracy: 0.1186 - val_loss: 10.9894 - learning_rate: 0.0010\n",
            "Epoch 6/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 2s/step - accuracy: 0.6934 - loss: 0.9175 - val_accuracy: 0.1661 - val_loss: 7.4885 - learning_rate: 0.0010\n",
            "Epoch 7/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 2s/step - accuracy: 0.7492 - loss: 0.7760 - val_accuracy: 0.1610 - val_loss: 7.2470 - learning_rate: 0.0010\n",
            "Epoch 8/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 2s/step - accuracy: 0.7930 - loss: 0.6149 - val_accuracy: 0.2644 - val_loss: 4.5432 - learning_rate: 0.0010\n",
            "Epoch 9/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 2s/step - accuracy: 0.7657 - loss: 0.6814 - val_accuracy: 0.3373 - val_loss: 3.6988 - learning_rate: 0.0010\n",
            "Epoch 10/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 2s/step - accuracy: 0.8113 - loss: 0.5813 - val_accuracy: 0.3424 - val_loss: 2.9445 - learning_rate: 0.0010\n",
            "Epoch 11/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 2s/step - accuracy: 0.8575 - loss: 0.4628 - val_accuracy: 0.5102 - val_loss: 2.0436 - learning_rate: 0.0010\n",
            "Epoch 12/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 2s/step - accuracy: 0.8503 - loss: 0.4225 - val_accuracy: 0.1814 - val_loss: 5.5148 - learning_rate: 0.0010\n",
            "Epoch 13/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 2s/step - accuracy: 0.8775 - loss: 0.3775 - val_accuracy: 0.4373 - val_loss: 2.5027 - learning_rate: 0.0010\n",
            "Epoch 14/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 2s/step - accuracy: 0.8956 - loss: 0.3051 - val_accuracy: 0.4966 - val_loss: 2.7436 - learning_rate: 0.0010\n",
            "Epoch 15/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 2s/step - accuracy: 0.9107 - loss: 0.2701 - val_accuracy: 0.5915 - val_loss: 1.5615 - learning_rate: 0.0010\n",
            "Epoch 16/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 2s/step - accuracy: 0.9273 - loss: 0.2350 - val_accuracy: 0.5898 - val_loss: 1.8763 - learning_rate: 0.0010\n",
            "Epoch 17/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 2s/step - accuracy: 0.9020 - loss: 0.2869 - val_accuracy: 0.4508 - val_loss: 2.5549 - learning_rate: 0.0010\n",
            "Epoch 18/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 2s/step - accuracy: 0.9243 - loss: 0.2301 - val_accuracy: 0.4983 - val_loss: 2.2026 - learning_rate: 0.0010\n",
            "Epoch 19/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 2s/step - accuracy: 0.8978 - loss: 0.3061 - val_accuracy: 0.5831 - val_loss: 2.0182 - learning_rate: 0.0010\n",
            "Epoch 20/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 2s/step - accuracy: 0.9312 - loss: 0.2219 - val_accuracy: 0.3915 - val_loss: 3.7443 - learning_rate: 0.0010\n",
            "Epoch 21/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 2s/step - accuracy: 0.9422 - loss: 0.1842 - val_accuracy: 0.7881 - val_loss: 0.7644 - learning_rate: 2.0000e-04\n",
            "Epoch 22/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 2s/step - accuracy: 0.9668 - loss: 0.1210 - val_accuracy: 0.8051 - val_loss: 0.6702 - learning_rate: 2.0000e-04\n",
            "Epoch 23/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 2s/step - accuracy: 0.9735 - loss: 0.0858 - val_accuracy: 0.7881 - val_loss: 0.7448 - learning_rate: 2.0000e-04\n",
            "Epoch 24/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 2s/step - accuracy: 0.9762 - loss: 0.0844 - val_accuracy: 0.8017 - val_loss: 0.7038 - learning_rate: 2.0000e-04\n",
            "Epoch 25/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 2s/step - accuracy: 0.9784 - loss: 0.0720 - val_accuracy: 0.7780 - val_loss: 0.7910 - learning_rate: 2.0000e-04\n",
            "Epoch 26/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 2s/step - accuracy: 0.9797 - loss: 0.0796 - val_accuracy: 0.8034 - val_loss: 0.6982 - learning_rate: 2.0000e-04\n",
            "Epoch 27/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 2s/step - accuracy: 0.9779 - loss: 0.0742 - val_accuracy: 0.8085 - val_loss: 0.7018 - learning_rate: 2.0000e-04\n",
            "Epoch 28/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 2s/step - accuracy: 0.9932 - loss: 0.0521 - val_accuracy: 0.8000 - val_loss: 0.7419 - learning_rate: 4.0000e-05\n",
            "Epoch 29/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 2s/step - accuracy: 0.9848 - loss: 0.0555 - val_accuracy: 0.7881 - val_loss: 0.8073 - learning_rate: 4.0000e-05\n",
            "Epoch 30/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 2s/step - accuracy: 0.9891 - loss: 0.0509 - val_accuracy: 0.8017 - val_loss: 0.7264 - learning_rate: 4.0000e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "\n",
        "test_loss, test_accuracy = model.evaluate(val_ds)\n",
        "print(f\"Validation Accuracy: {test_accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhLOh16YGvuq",
        "outputId": "e69c4ee2-3d19-456b-fac0-884f70370104"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 386ms/step - accuracy: 0.8195 - loss: 0.6441\n",
            "Validation Accuracy: 80.51%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. Predictions + classification report\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "for images, labels in val_ds:\n",
        "    preds = model.predict(images, verbose=0)\n",
        "    y_true.extend(np.argmax(labels.numpy(), axis=1))\n",
        "    y_pred.extend(np.argmax(preds, axis=1))\n",
        "\n",
        "print(classification_report(y_true, y_pred, target_names=class_names, zero_division=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMpiWmF9G_fE",
        "outputId": "be93469c-01aa-49fb-a1d9-2bbf09b5df3b"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                             precision    recall  f1-score   support\n",
            "\n",
            "              Pepper__bell___Bacterial_spot       0.85      0.83      0.84        41\n",
            "                     Pepper__bell___healthy       1.00      0.77      0.87        39\n",
            "                      Potato___Early_blight       0.93      0.91      0.92        43\n",
            "                       Potato___Late_blight       0.59      0.89      0.71        38\n",
            "                           Potato___healthy       0.97      0.91      0.94        35\n",
            "                      Tomato_Bacterial_spot       0.53      1.00      0.69        33\n",
            "                        Tomato_Early_blight       0.67      0.42      0.52        38\n",
            "                         Tomato_Late_blight       0.79      0.64      0.71        47\n",
            "                           Tomato_Leaf_Mold       0.81      0.76      0.78        33\n",
            "                  Tomato_Septoria_leaf_spot       0.84      0.58      0.69        36\n",
            "Tomato_Spider_mites_Two_spotted_spider_mite       0.73      0.88      0.80        40\n",
            "                        Tomato__Target_Spot       0.77      0.88      0.82        34\n",
            "      Tomato__Tomato_YellowLeaf__Curl_Virus       0.93      0.78      0.85        50\n",
            "                Tomato__Tomato_mosaic_virus       0.98      0.92      0.95        48\n",
            "                             Tomato_healthy       1.00      0.94      0.97        35\n",
            "\n",
            "                                   accuracy                           0.81       590\n",
            "                                  macro avg       0.82      0.81      0.80       590\n",
            "                               weighted avg       0.83      0.81      0.81       590\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model save:\n",
        "\n",
        "model.save('custom_cnn_plant_disease.keras')\n",
        "print(\"Model saved as 'custom_cnn_plant_disease.keras'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1mknXKtHvo-",
        "outputId": "c84aa7fc-114d-48a5-c7df-570978721af5"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved as 'custom_cnn_plant_disease.keras'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to predict on new images\n",
        "\n",
        "def predict_disease(image_path):\n",
        "    img = tf.keras.preprocessing.image.load_img(image_path, target_size=img_size)\n",
        "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array = img_array / 255.0  # Normalize\n",
        "\n",
        "    prediction = model.predict(img_array)\n",
        "    predicted_class = np.argmax(prediction, axis=1)[0]\n",
        "    confidence = np.max(prediction)\n",
        "\n",
        "    return class_names[predicted_class], confidence"
      ],
      "metadata": {
        "id": "G7fCWuVSH1G0"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the prediction function with a sample image_1\n",
        "\n",
        "sample_image_path = \"/content/PlantVillage/Tomato_Bacterial_spot/00416648-be6e-4bd4-bc8d-82f43f8a7240___GCREC_Bact.Sp 3110.JPG\"\n",
        "\n",
        "predicted_class, confidence = predict_disease(sample_image_path)\n",
        "print(f\"Predicted Disease: {predicted_class} with confidence: {confidence:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PybaZTa9IADw",
        "outputId": "e120563c-a970-4233-fce5-15ce71628e1a"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "Predicted Disease: Tomato_Bacterial_spot with confidence: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the prediction function with a sample image_2\n",
        "\n",
        "sample_image_path = \"/content/PlantVillage/Tomato__Tomato_mosaic_virus/000ec6ea-9063-4c33-8abe-d58ca8a88878___PSU_CG 2169.JPG\"\n",
        "\n",
        "predicted_class, confidence = predict_disease(sample_image_path)\n",
        "print(f\"Predicted Disease: {predicted_class} with confidence: {confidence:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MG3ZOTZAIF-F",
        "outputId": "04958498-7aa6-4201-8523-9bd8ab458a64"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "Predicted Disease: Tomato__Tomato_mosaic_virus with confidence: 0.99\n"
          ]
        }
      ]
    }
  ]
}